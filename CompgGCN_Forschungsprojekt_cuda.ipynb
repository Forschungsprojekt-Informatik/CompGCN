{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWywcrOLvmfN"
      },
      "source": [
        "Please enable GPU under Runtime > Change Runtime to make use of GPU Hardware Accelaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m2m-qWdmiNa",
        "outputId": "2eeb5830-0da5-44a6-ead5-dca42cca6058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1TOyBuDniO9",
        "outputId": "ffe3639a-6a43-48b1-ab41-bf2489296111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Drive\n",
            "Cloning into 'CompGCN'...\n",
            "remote: Enumerating objects: 387, done.\u001b[K\n",
            "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 387 (delta 167), reused 132 (delta 128), pack-reused 167\u001b[K\n",
            "Receiving objects: 100% (387/387), 10.64 MiB | 15.29 MiB/s, done.\n",
            "Resolving deltas: 100% (244/244), done.\n",
            "/content/drive/MyDrive/Drive/CompGCN\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Drive/\n",
        "! rm -r CompGCN\n",
        "! git clone https://github.com/Forschungsprojekt-Informatik/CompGCN.git\n",
        "%cd CompGCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KONC4x15hYsY",
        "outputId": "72d6b5b5-b9d4-48b6-973f-68bb776da00c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (4.5.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.6.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n"
          ]
        }
      ],
      "source": [
        "pip install torch==1.13.1 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLytZyEVh7Zq",
        "outputId": "814f007b-c982-4e8f-825a-50f2cf111b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu118.html\n",
            "Collecting torch-scatter==2.1.0\n",
            "  Using cached torch_scatter-2.1.0.tar.gz (106 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.0-cp39-cp39-linux_x86_64.whl size=3509112 sha256=f1badfe6b3687d706478ec16f5fec0c711522aec0fe96ca6cc141b34767fea26\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/33/3c/b02defb8e41252b9073b3b98433e082a8fb9aa8945127ffcbe\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install torch-scatter==2.1.0 -f https://data.pyg.org/whl/torch-1.13.1+cu117.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG3FiUOah8bn",
        "outputId": "06dc28d9-200c-4f06-e501-284c3e29fe8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.13.1)\n",
            "Collecting ordered_set==4.1.0\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting numpy==1.24.1\n",
            "  Downloading numpy-1.24.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch_scatter==2.1.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.1.0)\n",
            "Collecting scikit_learn==1.2.0\n",
            "  Downloading scikit_learn-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (11.7.99)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (11.7.99)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 5)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 1)) (67.6.1)\n",
            "Installing collected packages: ordered_set, numpy, scikit_learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.1 ordered_set-4.1.0 scikit_learn-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upHnCc1rigWC",
        "outputId": "0d18eb46-a66e-4ec3-a55f-9079b098adf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘log’: File exists\n",
            "mkdir: cannot create directory ‘checkpoints’: File exists\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "Archive:  data_compressed/codex-l.zip\n",
            "replace data/codex-l/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/codex-l/test.txt   \n",
            "  inflating: data/codex-l/train.txt  \n",
            "  inflating: data/codex-l/valid.txt  \n",
            "Archive:  data_compressed/codex-m.zip\n",
            "replace data/codex-m/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/codex-m/test.txt   \n",
            "  inflating: data/codex-m/test_negatives.txt  \n",
            "  inflating: data/codex-m/train.txt  \n",
            "  inflating: data/codex-m/valid.txt  \n",
            "  inflating: data/codex-m/valid_negatives.txt  \n",
            "Archive:  data_compressed/codex-s.zip\n",
            "replace data/codex-s/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/codex-s/test.txt   \n",
            "  inflating: data/codex-s/test_negatives.txt  \n",
            "  inflating: data/codex-s/train.txt  \n",
            "  inflating: data/codex-s/valid.txt  \n",
            "  inflating: data/codex-s/valid_negatives.txt  \n",
            "Archive:  data_compressed/codex-xxs.zip\n",
            "replace data/codex-xxs/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/codex-xxs/test.txt  \n",
            "  inflating: data/codex-xxs/test_negatives.txt  \n",
            "  inflating: data/codex-xxs/train.txt  \n",
            "  inflating: data/codex-xxs/valid.txt  \n",
            "  inflating: data/codex-xxs/valid_negatives.txt  \n",
            "Archive:  data_compressed/FB15k-237.zip\n",
            "replace data/FB15k-237/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/FB15k-237/test.txt  \n",
            "  inflating: data/FB15k-237/train.txt  \n",
            "  inflating: data/FB15k-237/valid.txt  \n",
            "Archive:  data_compressed/WN18RR.zip\n",
            "replace data/WN18RR/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/WN18RR/test.txt    \n",
            "  inflating: data/WN18RR/train.txt   \n",
            "  inflating: data/WN18RR/valid.txt   \n"
          ]
        }
      ],
      "source": [
        "! chmod +x preprocess.sh\n",
        "! ./preprocess.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_qs7FNIlNIV",
        "outputId": "45e3f3ba-c637-4a5a-cb74-9d8643a89ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the GPU available: True\n",
            "2023-03-30 09:31:41,792 - [INFO] - {'name': 'TransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41', 'dataset': 'codex-s', 'model': 'compgcn', 'score_func': 'transe', 'opn': 'sub', 'batch_size': 128, 'gamma': 9.0, 'gpu': '0', 'max_epochs': 500, 'l2': 0.0, 'lr': 0.001, 'lbl_smooth': 0.1, 'num_workers': 10, 'seed': 41504, 'restore': False, 'bias': False, 'num_bases': -1, 'init_dim': 200, 'gcn_dim': 200, 'embed_dim': None, 'gcn_layer': 1, 'dropout': 0.1, 'hid_drop': 0.1, 'disable_gnn_encoder': False, 'hid_drop2': 0.3, 'feat_drop': 0.3, 'k_w': 10, 'k_h': 20, 'num_filt': 200, 'ker_sz': 7, 'log_dir': './log/', 'config_dir': './config/'}\n",
            "{'batch_size': 128,\n",
            " 'bias': False,\n",
            " 'config_dir': './config/',\n",
            " 'dataset': 'codex-s',\n",
            " 'disable_gnn_encoder': False,\n",
            " 'dropout': 0.1,\n",
            " 'embed_dim': None,\n",
            " 'feat_drop': 0.3,\n",
            " 'gamma': 9.0,\n",
            " 'gcn_dim': 200,\n",
            " 'gcn_layer': 1,\n",
            " 'gpu': '0',\n",
            " 'hid_drop': 0.1,\n",
            " 'hid_drop2': 0.3,\n",
            " 'init_dim': 200,\n",
            " 'k_h': 20,\n",
            " 'k_w': 10,\n",
            " 'ker_sz': 7,\n",
            " 'l2': 0.0,\n",
            " 'lbl_smooth': 0.1,\n",
            " 'log_dir': './log/',\n",
            " 'lr': 0.001,\n",
            " 'max_epochs': 500,\n",
            " 'model': 'compgcn',\n",
            " 'name': 'TransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41',\n",
            " 'num_bases': -1,\n",
            " 'num_filt': 200,\n",
            " 'num_workers': 10,\n",
            " 'opn': 'sub',\n",
            " 'restore': False,\n",
            " 'score_func': 'transe',\n",
            " 'seed': 41504}\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-03-30 09:31:45,501 - [INFO] - [E:0| 0]: Train Loss:0.34271,  Val MRR:0.0\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:48,134 - [INFO] - [Epoch:0]:  Training Loss:0.2857\n",
            "\n",
            "/content/drive/MyDrive/Drive/CompGCN/run.py:317: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:413.)\n",
            "  pred \t\t\t= torch.where(label.byte(), -torch.ones_like(pred) * 10000000, pred)\n",
            "2023-03-30 09:31:48,717 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:49,539 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:49,840 - [INFO] - [Epoch 0 valid]: MRR: Tail : 0.01479, Head : 0.01439, Avg : 0.01459\n",
            "2023-03-30 09:31:49,871 - [INFO] - [Epoch 0]: Training Loss: 0.28569, Valid MRR: 0.01459\n",
            "\n",
            "\n",
            "2023-03-30 09:31:50,348 - [INFO] - [E:1| 0]: Train Loss:0.18281,  Val MRR:0.01459\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:52,552 - [INFO] - [Epoch:1]:  Training Loss:0.2851\n",
            "\n",
            "2023-03-30 09:31:52,958 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:53,686 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:54,025 - [INFO] - [Epoch 1 valid]: MRR: Tail : 0.01498, Head : 0.01438, Avg : 0.01468\n",
            "2023-03-30 09:31:54,057 - [INFO] - [Epoch 1]: Training Loss: 0.28509, Valid MRR: 0.01468\n",
            "\n",
            "\n",
            "2023-03-30 09:31:54,561 - [INFO] - [E:2| 0]: Train Loss:0.3412,  Val MRR:0.01468\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:56,775 - [INFO] - [Epoch:2]:  Training Loss:0.2851\n",
            "\n",
            "2023-03-30 09:31:57,177 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:57,888 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:31:58,210 - [INFO] - [Epoch 2 valid]: MRR: Tail : 0.01499, Head : 0.01438, Avg : 0.01469\n",
            "2023-03-30 09:31:58,241 - [INFO] - [Epoch 2]: Training Loss: 0.28506, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:31:58,694 - [INFO] - [E:3| 0]: Train Loss:0.2538,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:01,307 - [INFO] - [Epoch:3]:  Training Loss:0.2852\n",
            "\n",
            "2023-03-30 09:32:01,908 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:02,961 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:03,403 - [INFO] - [Epoch 3 valid]: MRR: Tail : 0.01498, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:03,404 - [INFO] - [Epoch 3]: Training Loss: 0.28515, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:04,083 - [INFO] - [E:4| 0]: Train Loss:0.21005,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:06,492 - [INFO] - [Epoch:4]:  Training Loss:0.2855\n",
            "\n",
            "2023-03-30 09:32:06,881 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:07,616 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:07,919 - [INFO] - [Epoch 4 valid]: MRR: Tail : 0.01499, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:07,920 - [INFO] - [Epoch 4]: Training Loss: 0.28553, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:08,375 - [INFO] - [E:5| 0]: Train Loss:0.25639,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:10,651 - [INFO] - [Epoch:5]:  Training Loss:0.2853\n",
            "\n",
            "2023-03-30 09:32:11,041 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:11,819 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:12,188 - [INFO] - [Epoch 5 valid]: MRR: Tail : 0.01499, Head : 0.0144, Avg : 0.01469\n",
            "2023-03-30 09:32:12,188 - [INFO] - [Epoch 5]: Training Loss: 0.28533, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:12,719 - [INFO] - [E:6| 0]: Train Loss:0.21442,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:15,037 - [INFO] - [Epoch:6]:  Training Loss:0.2852\n",
            "\n",
            "2023-03-30 09:32:15,603 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:16,625 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:17,190 - [INFO] - [Epoch 6 valid]: MRR: Tail : 0.01499, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:17,191 - [INFO] - [Epoch 6]: Training Loss: 0.28523, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:17,803 - [INFO] - [E:7| 0]: Train Loss:0.26399,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:20,570 - [INFO] - [Epoch:7]:  Training Loss:0.2855\n",
            "\n",
            "2023-03-30 09:32:21,015 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:21,756 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:22,085 - [INFO] - [Epoch 7 valid]: MRR: Tail : 0.01499, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:22,086 - [INFO] - [Epoch 7]: Training Loss: 0.28548, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:22,563 - [INFO] - [E:8| 0]: Train Loss:0.24135,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:24,777 - [INFO] - [Epoch:8]:  Training Loss:0.2852\n",
            "\n",
            "2023-03-30 09:32:25,195 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:25,915 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:26,232 - [INFO] - [Epoch 8 valid]: MRR: Tail : 0.01499, Head : 0.0144, Avg : 0.01469\n",
            "2023-03-30 09:32:26,232 - [INFO] - [Epoch 8]: Training Loss: 0.28519, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:26,683 - [INFO] - [E:9| 0]: Train Loss:0.2936,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:28,919 - [INFO] - [Epoch:9]:  Training Loss:0.2857\n",
            "\n",
            "2023-03-30 09:32:29,325 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:30,068 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:30,384 - [INFO] - [Epoch 9 valid]: MRR: Tail : 0.01499, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:30,385 - [INFO] - [Epoch 9]: Training Loss: 0.28571, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:30,931 - [INFO] - [E:10| 0]: Train Loss:0.27172,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:33,788 - [INFO] - [Epoch:10]:  Training Loss:0.2857\n",
            "\n",
            "2023-03-30 09:32:34,368 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:35,342 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:35,785 - [INFO] - [Epoch 10 valid]: MRR: Tail : 0.01499, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:35,787 - [INFO] - [Epoch 10]: Training Loss: 0.28572, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:36,463 - [INFO] - [E:11| 0]: Train Loss:0.23234,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:38,833 - [INFO] - [Epoch:11]:  Training Loss:0.2858\n",
            "\n",
            "2023-03-30 09:32:39,231 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:39,999 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:40,312 - [INFO] - [Epoch 11 valid]: MRR: Tail : 0.01499, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:40,313 - [INFO] - [Epoch 11]: Training Loss: 0.28576, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:40,787 - [INFO] - [E:12| 0]: Train Loss:0.27778,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:43,007 - [INFO] - [Epoch:12]:  Training Loss:0.2855\n",
            "\n",
            "2023-03-30 09:32:43,400 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:44,123 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:44,434 - [INFO] - [Epoch 12 valid]: MRR: Tail : 0.01499, Head : 0.01439, Avg : 0.01469\n",
            "2023-03-30 09:32:44,435 - [INFO] - Gamma decay on saturation, updated value of gamma: 4.0\n",
            "2023-03-30 09:32:44,435 - [INFO] - [Epoch 12]: Training Loss: 0.28553, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:44,915 - [INFO] - [E:13| 0]: Train Loss:0.4064,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:47,222 - [INFO] - [Epoch:13]:  Training Loss:0.2883\n",
            "\n",
            "2023-03-30 09:32:47,785 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:48,886 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:49,355 - [INFO] - [Epoch 13 valid]: MRR: Tail : 0.01507, Head : 0.01426, Avg : 0.01466\n",
            "2023-03-30 09:32:49,357 - [INFO] - [Epoch 13]: Training Loss: 0.28828, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:49,990 - [INFO] - [E:14| 0]: Train Loss:0.25291,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:52,632 - [INFO] - [Epoch:14]:  Training Loss:0.2882\n",
            "\n",
            "2023-03-30 09:32:53,015 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:53,758 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:54,063 - [INFO] - [Epoch 14 valid]: MRR: Tail : 0.01504, Head : 0.01426, Avg : 0.01465\n",
            "2023-03-30 09:32:54,063 - [INFO] - [Epoch 14]: Training Loss: 0.28822, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:54,499 - [INFO] - [E:15| 0]: Train Loss:0.34101,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:56,769 - [INFO] - [Epoch:15]:  Training Loss:0.2886\n",
            "\n",
            "2023-03-30 09:32:57,182 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:57,903 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:32:58,232 - [INFO] - [Epoch 15 valid]: MRR: Tail : 0.01504, Head : 0.01426, Avg : 0.01465\n",
            "2023-03-30 09:32:58,232 - [INFO] - [Epoch 15]: Training Loss: 0.28858, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:32:58,693 - [INFO] - [E:16| 0]: Train Loss:0.21537,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:00,942 - [INFO] - [Epoch:16]:  Training Loss:0.2883\n",
            "\n",
            "2023-03-30 09:33:01,347 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:02,093 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:02,414 - [INFO] - [Epoch 16 valid]: MRR: Tail : 0.01504, Head : 0.01426, Avg : 0.01465\n",
            "2023-03-30 09:33:02,414 - [INFO] - [Epoch 16]: Training Loss: 0.28833, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:03,055 - [INFO] - [E:17| 0]: Train Loss:0.32225,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:05,959 - [INFO] - [Epoch:17]:  Training Loss:0.2884\n",
            "\n",
            "2023-03-30 09:33:06,540 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:07,524 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:07,915 - [INFO] - [Epoch 17 valid]: MRR: Tail : 0.01504, Head : 0.01427, Avg : 0.01465\n",
            "2023-03-30 09:33:07,916 - [INFO] - [Epoch 17]: Training Loss: 0.28841, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:08,572 - [INFO] - [E:18| 0]: Train Loss:0.26162,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:10,821 - [INFO] - [Epoch:18]:  Training Loss:0.2888\n",
            "\n",
            "2023-03-30 09:33:11,223 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:11,944 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:12,253 - [INFO] - [Epoch 18 valid]: MRR: Tail : 0.01504, Head : 0.01426, Avg : 0.01465\n",
            "2023-03-30 09:33:12,253 - [INFO] - [Epoch 18]: Training Loss: 0.28882, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:12,766 - [INFO] - [E:19| 0]: Train Loss:0.26672,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:14,988 - [INFO] - [Epoch:19]:  Training Loss:0.2887\n",
            "\n",
            "2023-03-30 09:33:15,424 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:16,141 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:16,462 - [INFO] - [Epoch 19 valid]: MRR: Tail : 0.01503, Head : 0.01427, Avg : 0.01465\n",
            "2023-03-30 09:33:16,462 - [INFO] - [Epoch 19]: Training Loss: 0.28874, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:16,886 - [INFO] - [E:20| 0]: Train Loss:0.19179,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:19,352 - [INFO] - [Epoch:20]:  Training Loss:0.2883\n",
            "\n",
            "2023-03-30 09:33:19,946 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:21,053 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:21,508 - [INFO] - [Epoch 20 valid]: MRR: Tail : 0.01503, Head : 0.01427, Avg : 0.01465\n",
            "2023-03-30 09:33:21,509 - [INFO] - [Epoch 20]: Training Loss: 0.28829, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:22,185 - [INFO] - [E:21| 0]: Train Loss:0.21391,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:24,859 - [INFO] - [Epoch:21]:  Training Loss:0.2882\n",
            "\n",
            "2023-03-30 09:33:25,273 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:26,004 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:26,319 - [INFO] - [Epoch 21 valid]: MRR: Tail : 0.01505, Head : 0.01425, Avg : 0.01465\n",
            "2023-03-30 09:33:26,320 - [INFO] - [Epoch 21]: Training Loss: 0.28821, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:26,779 - [INFO] - [E:22| 0]: Train Loss:0.54106,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:29,031 - [INFO] - [Epoch:22]:  Training Loss:0.2888\n",
            "\n",
            "2023-03-30 09:33:29,437 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:30,266 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:30,720 - [INFO] - [Epoch 22 valid]: MRR: Tail : 0.01503, Head : 0.01427, Avg : 0.01465\n",
            "2023-03-30 09:33:30,721 - [INFO] - [Epoch 22]: Training Loss: 0.28878, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:31,374 - [INFO] - [E:23| 0]: Train Loss:0.26854,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:34,360 - [INFO] - [Epoch:23]:  Training Loss:0.2883\n",
            "\n",
            "2023-03-30 09:33:35,197 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:36,559 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:37,068 - [INFO] - [Epoch 23 valid]: MRR: Tail : 0.01503, Head : 0.01427, Avg : 0.01465\n",
            "2023-03-30 09:33:37,069 - [INFO] - [Epoch 23]: Training Loss: 0.28826, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:37,678 - [INFO] - [E:24| 0]: Train Loss:0.21178,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:40,407 - [INFO] - [Epoch:24]:  Training Loss:0.288\n",
            "\n",
            "2023-03-30 09:33:40,814 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:41,566 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:41,881 - [INFO] - [Epoch 24 valid]: MRR: Tail : 0.01504, Head : 0.01427, Avg : 0.01465\n",
            "2023-03-30 09:33:41,882 - [INFO] - [Epoch 24]: Training Loss: 0.28805, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:42,359 - [INFO] - [E:25| 0]: Train Loss:0.22712,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:44,634 - [INFO] - [Epoch:25]:  Training Loss:0.2884\n",
            "\n",
            "2023-03-30 09:33:45,058 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:45,788 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:46,112 - [INFO] - [Epoch 25 valid]: MRR: Tail : 0.01504, Head : 0.01427, Avg : 0.01466\n",
            "2023-03-30 09:33:46,112 - [INFO] - [Epoch 25]: Training Loss: 0.28837, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:46,605 - [INFO] - [E:26| 0]: Train Loss:0.2153,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:48,871 - [INFO] - [Epoch:26]:  Training Loss:0.2884\n",
            "\n",
            "2023-03-30 09:33:49,295 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:50,025 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:50,341 - [INFO] - [Epoch 26 valid]: MRR: Tail : 0.01504, Head : 0.01427, Avg : 0.01466\n",
            "2023-03-30 09:33:50,342 - [INFO] - [Epoch 26]: Training Loss: 0.2884, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:51,004 - [INFO] - [E:27| 0]: Train Loss:0.27094,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:53,920 - [INFO] - [Epoch:27]:  Training Loss:0.2883\n",
            "\n",
            "2023-03-30 09:33:54,496 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:55,486 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:55,924 - [INFO] - [Epoch 27 valid]: MRR: Tail : 0.01502, Head : 0.01427, Avg : 0.01465\n",
            "2023-03-30 09:33:55,926 - [INFO] - [Epoch 27]: Training Loss: 0.28827, Valid MRR: 0.01469\n",
            "\n",
            "\n",
            "2023-03-30 09:33:56,538 - [INFO] - [E:28| 0]: Train Loss:0.42305,  Val MRR:0.01469\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:58,841 - [INFO] - [Epoch:28]:  Training Loss:0.2884\n",
            "\n",
            "2023-03-30 09:33:59,247 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:33:59,994 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:34:00,297 - [INFO] - [Epoch 28 valid]: MRR: Tail : 0.01504, Head : 0.01427, Avg : 0.01466\n",
            "2023-03-30 09:34:00,297 - [INFO] - Early Stopping!!\n",
            "2023-03-30 09:34:00,297 - [INFO] - Loading best model, Evaluating on Test data\n",
            "2023-03-30 09:34:00,745 - [INFO] - [Test, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:34:01,492 - [INFO] - [Test, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_09_31_41\n",
            "2023-03-30 09:34:01,801 - [INFO] - [Epoch 28 test]: MRR: Tail : 0.01194, Head : 0.01226, Avg : 0.0121\n"
          ]
        }
      ],
      "source": [
        "! python run.py -name TransE_Sub_codex_s_with_GCN_model -score_func transe -opn sub -gamma 9 -init_dim 200 -hid_drop 0.1 -data codex-s"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
