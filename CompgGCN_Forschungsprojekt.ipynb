{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m2m-qWdmiNa",
        "outputId": "b4373198-cf00-45b6-bbbc-174cab8005bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Drive/\n",
        "!git clone https://github.com/Forschungsprojekt-Informatik/CompGCN.git\n",
        "%cd CompGCN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1TOyBuDniO9",
        "outputId": "2f74d575-98e5-40f9-9691-f42f529cf18d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Drive\n",
            "Cloning into 'CompGCN'...\n",
            "remote: Enumerating objects: 374, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 374 (delta 159), reused 126 (delta 125), pack-reused 167\u001b[K\n",
            "Receiving objects: 100% (374/374), 10.64 MiB | 14.90 MiB/s, done.\n",
            "Resolving deltas: 100% (236/236), done.\n",
            "/content/drive/MyDrive/Drive/CompGCN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.13.1 --extra-index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KONC4x15hYsY",
        "outputId": "7e3c3fe4-8d6a-41a3-977c-5bf732c90cae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==1.13.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.13.1%2Bcpu-cp39-cp39-linux_x86_64.whl (199.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.13.1+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-scatter==2.1.0 -f https://data.pyg.org/whl/torch-1.13.1+cpu.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLytZyEVh7Zq",
        "outputId": "cf7ed84f-199a-4aae-863b-df12ab44c07b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cpu.html\n",
            "Collecting torch-scatter==2.1.0\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_scatter-2.1.0%2Bpt113cpu-cp39-cp39-linux_x86_64.whl (491 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.7/491.7 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG3FiUOah8bn",
        "outputId": "e6ed14ba-5004-4314-b138-53ed0fa30b5d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.13.1+cpu)\n",
            "Collecting ordered_set==4.1.0\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting numpy==1.24.1\n",
            "  Downloading numpy-1.24.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch_scatter==2.1.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.1.0+pt113cpu)\n",
            "Collecting scikit_learn==1.2.0\n",
            "  Downloading scikit_learn-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 5)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.2.0->-r requirements.txt (line 5)) (1.1.1)\n",
            "Installing collected packages: ordered_set, numpy, scikit_learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.1 ordered_set-4.1.0 scikit_learn-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x preprocess.sh\n",
        "! ./preprocess.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upHnCc1rigWC",
        "outputId": "20dc6cf0-59e6-4427-9a6d-a4da8af67540"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data_compressed/codex-l.zip\n",
            "  inflating: data/codex-l/test.txt   \n",
            "  inflating: data/codex-l/train.txt  \n",
            "  inflating: data/codex-l/valid.txt  \n",
            "Archive:  data_compressed/codex-m.zip\n",
            "  inflating: data/codex-m/test.txt   \n",
            "  inflating: data/codex-m/test_negatives.txt  \n",
            "  inflating: data/codex-m/train.txt  \n",
            "  inflating: data/codex-m/valid.txt  \n",
            "  inflating: data/codex-m/valid_negatives.txt  \n",
            "Archive:  data_compressed/codex-s.zip\n",
            "  inflating: data/codex-s/test.txt   \n",
            "  inflating: data/codex-s/test_negatives.txt  \n",
            "  inflating: data/codex-s/train.txt  \n",
            "  inflating: data/codex-s/valid.txt  \n",
            "  inflating: data/codex-s/valid_negatives.txt  \n",
            "Archive:  data_compressed/codex-xxs.zip\n",
            "  inflating: data/codex-xxs/test.txt  \n",
            "  inflating: data/codex-xxs/test_negatives.txt  \n",
            "  inflating: data/codex-xxs/train.txt  \n",
            "  inflating: data/codex-xxs/valid.txt  \n",
            "  inflating: data/codex-xxs/valid_negatives.txt  \n",
            "Archive:  data_compressed/FB15k-237.zip\n",
            "   creating: data/FB15k-237/\n",
            "  inflating: data/FB15k-237/test.txt  \n",
            "  inflating: data/FB15k-237/train.txt  \n",
            "  inflating: data/FB15k-237/valid.txt  \n",
            "Archive:  data_compressed/WN18RR.zip\n",
            "   creating: data/WN18RR/\n",
            "  inflating: data/WN18RR/test.txt    \n",
            "  inflating: data/WN18RR/train.txt   \n",
            "  inflating: data/WN18RR/valid.txt   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python run.py -name TransE_Sub_codex_s_with_GCN_model -score_func transe -opn sub -gamma 9 -init_dim 200 -hid_drop 0.1 -data codex-s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_qs7FNIlNIV",
        "outputId": "1d5f8bff-f453-4048-ed5c-378b5752172d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available: False\n",
            "2023-03-30 08:14:34,032 - [INFO] - {'name': 'TransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34', 'dataset': 'codex-s', 'model': 'compgcn', 'score_func': 'transe', 'opn': 'sub', 'batch_size': 128, 'gamma': 9.0, 'gpu': '0', 'max_epochs': 500, 'l2': 0.0, 'lr': 0.001, 'lbl_smooth': 0.1, 'num_workers': 10, 'seed': 41504, 'restore': False, 'bias': False, 'num_bases': -1, 'init_dim': 200, 'gcn_dim': 200, 'embed_dim': None, 'gcn_layer': 1, 'dropout': 0.1, 'hid_drop': 0.1, 'disable_gnn_encoder': False, 'hid_drop2': 0.3, 'feat_drop': 0.3, 'k_w': 10, 'k_h': 20, 'num_filt': 200, 'ker_sz': 7, 'log_dir': './log/', 'config_dir': './config/'}\n",
            "{'batch_size': 128,\n",
            " 'bias': False,\n",
            " 'config_dir': './config/',\n",
            " 'dataset': 'codex-s',\n",
            " 'disable_gnn_encoder': False,\n",
            " 'dropout': 0.1,\n",
            " 'embed_dim': None,\n",
            " 'feat_drop': 0.3,\n",
            " 'gamma': 9.0,\n",
            " 'gcn_dim': 200,\n",
            " 'gcn_layer': 1,\n",
            " 'gpu': '0',\n",
            " 'hid_drop': 0.1,\n",
            " 'hid_drop2': 0.3,\n",
            " 'init_dim': 200,\n",
            " 'k_h': 20,\n",
            " 'k_w': 10,\n",
            " 'ker_sz': 7,\n",
            " 'l2': 0.0,\n",
            " 'lbl_smooth': 0.1,\n",
            " 'log_dir': './log/',\n",
            " 'lr': 0.001,\n",
            " 'max_epochs': 500,\n",
            " 'model': 'compgcn',\n",
            " 'name': 'TransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34',\n",
            " 'num_bases': -1,\n",
            " 'num_filt': 200,\n",
            " 'num_workers': 10,\n",
            " 'opn': 'sub',\n",
            " 'restore': False,\n",
            " 'score_func': 'transe',\n",
            " 'seed': 41504}\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-03-30 08:14:36,895 - [INFO] - [E:0| 0]: Train Loss:0.34283,  Val MRR:0.0\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:16:53,811 - [INFO] - [Epoch:0]:  Training Loss:0.2856\n",
            "\n",
            "/content/drive/MyDrive/Drive/CompGCN/run.py:317: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:413.)\n",
            "  pred \t\t\t= torch.where(label.byte(), -torch.ones_like(pred) * 10000000, pred)\n",
            "2023-03-30 08:16:54,938 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:17:05,096 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:17:13,547 - [INFO] - [Epoch 0 valid]: MRR: Tail : 0.01429, Head : 0.01453, Avg : 0.01441\n",
            "2023-03-30 08:17:13,628 - [INFO] - [Epoch 0]: Training Loss: 0.28564, Valid MRR: 0.01441\n",
            "\n",
            "\n",
            "2023-03-30 08:17:21,029 - [INFO] - [E:1| 0]: Train Loss:0.28855,  Val MRR:0.01441\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:19:45,497 - [INFO] - [Epoch:1]:  Training Loss:0.2859\n",
            "\n",
            "2023-03-30 08:19:46,585 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:19:56,806 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:20:03,581 - [INFO] - [Epoch 1 valid]: MRR: Tail : 0.01443, Head : 0.01454, Avg : 0.01449\n",
            "2023-03-30 08:20:03,612 - [INFO] - [Epoch 1]: Training Loss: 0.28591, Valid MRR: 0.01449\n",
            "\n",
            "\n",
            "2023-03-30 08:20:06,301 - [INFO] - [E:2| 0]: Train Loss:0.27664,  Val MRR:0.01449\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:22:21,925 - [INFO] - [Epoch:2]:  Training Loss:0.2854\n",
            "\n",
            "2023-03-30 08:22:23,069 - [INFO] - [Valid, Tail_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:22:32,829 - [INFO] - [Valid, Head_Batch Step 0]\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n",
            "2023-03-30 08:22:40,095 - [INFO] - [Epoch 2 valid]: MRR: Tail : 0.01444, Head : 0.01454, Avg : 0.01449\n",
            "2023-03-30 08:22:40,096 - [INFO] - [Epoch 2]: Training Loss: 0.28541, Valid MRR: 0.01449\n",
            "\n",
            "\n",
            "2023-03-30 08:22:42,287 - [INFO] - [E:3| 0]: Train Loss:0.18392,  Val MRR:0.01449\tTransE_Sub_codex_s_with_GCN_model_30_03_2023_08_14_34\n"
          ]
        }
      ]
    }
  ]
}